{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase of the DQN agent\n",
    "This notebook will showcase the code for the DQN agent found in \"pendulumCrane/agent/dqn_agent.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import pendulumCrane\n",
    "\n",
    "from gym import wrappers, logger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "We use a replay buffer to store transitions and sample from this buffer when training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replay buffer\n",
    "class ReplayMemory(object):\n",
    "    \"\"\"Experience Replay Memory\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        #self.size = size\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    \n",
    "    def add(self, *args):\n",
    "        \"\"\"Add experience to memory.\"\"\"\n",
    "        self.memory.append([*args])\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample batch of experiences from memory with replacement.\"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def count(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n",
    "The network is a standard feed forward neural net, with 3 hidden layers and 128 hidden units in each, with dropout between each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN class\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, learning_rate):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden_size = 128\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(n_inputs,self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc5 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, n_outputs)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # define dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Standard FNN layers\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "\n",
    "        return F.softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and reward calculation\n",
    "To use a continuous environment, we pass the neuron index of the selected action through a small pseudo DAC, which converts it to a voltage in the D2C function.\n",
    "\n",
    "We also calculate the reward used internally in the agent, as the environment was shared between DQN and DPPG, which uses different reward structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index of the output neuron, to a continuous value for the environment\n",
    "def D2C(discrete_action):\n",
    "    pos_voltage = 2.0 # Go left\n",
    "    neg_voltage = -2.0 # Go right\n",
    "    volt_range = np.array([-9.0, -7.0, -5.0, -2.0, -1.0, -0.1, 0.0, 0.1, 1.0, 2.0, 5.0, 7.0, 9.0])\n",
    "    output = volt_range[int(discrete_action)]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def agent_reward(action, next_state, reward_array, old_state):\n",
    "\n",
    "    # Calculate distance \n",
    "    x_goal = next_state[2]\n",
    "    x_pos = next_state[0]\n",
    "    distance = x_pos - x_goal\n",
    "\n",
    "    x_goal_old = old_state[2]\n",
    "    x_pos_old = old_state[0]\n",
    "    old_distance = x_pos_old - x_goal_old\n",
    "\n",
    "    # Calculate end effector position of pendulum\n",
    "    theta = next_state[1]\n",
    "\n",
    "    pen_length = 0.7 # Length of pendulum - Placeholder\n",
    "    theta_pos = x_pos + math.sin(theta)*pen_length\n",
    "\n",
    "    # Use distance of end effector instead of sledge\n",
    "    distance_pendulum = theta_pos - x_goal\n",
    "\n",
    "    dist_dif = distance**2 - old_distance**2\n",
    "\n",
    "    reward = 0\n",
    "    reward_type = 0\n",
    "    # Base reward:\n",
    "    if dist_dif > 0:\n",
    "        reward = -1\n",
    "        reward_type = 1\n",
    "    elif dist_dif == 0:\n",
    "        reward = 1\n",
    "        reward_type = 0\n",
    "    elif dist_dif < 0:\n",
    "        reward = 1\n",
    "        reward_type = 2\n",
    "\n",
    "\n",
    "    reward_array[reward_type] += 1 \n",
    "\n",
    "\n",
    "    # Distance bonus\n",
    "    dist_bonus = 2 - abs(distance)*10\n",
    "    reward = reward + dist_bonus\n",
    "\n",
    "    # Theta_pos penalty\n",
    "    theta_p = next_state[1]\n",
    "    theta_p = (x_pos+math.sin(theta_p)*0.7)-x_pos\n",
    "    theta_penalty = abs(theta_p)*2\n",
    "\n",
    "    reward = reward - theta_penalty\n",
    "    return reward, reward_array\n",
    "\n",
    "def random_action(n_outputs):\n",
    "    action = np.random.randint(n_outputs,size=1)\n",
    "    action = float(action)\n",
    "    return action\n",
    "\n",
    "\n",
    "\n",
    "def select_action(state, step_count):\n",
    "    # Determine if we are taking a random action or not\n",
    "    Eps_start = 0.9\n",
    "    Eps_end = 0.15\n",
    "    Eps_decay = 25\n",
    "\n",
    "    sample = random.random()\n",
    "    Eps_threshold = Eps_end + (Eps_start - Eps_end) * math.exp(-1. *step_count/Eps_decay)\n",
    "    #step_count += 1\n",
    "\n",
    "    action_type = \"R\" # Random action\n",
    "\n",
    "    if sample > Eps_threshold: \n",
    "        action_type = \"Q\" # Q action\n",
    "\n",
    "    return action_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "The optimizer samples random transitions from the replay buffer and uses them as a basis for training the network, based on the Huber Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_optimizer(n_inputs):\n",
    "    if replay_memory.count() < batch_size:\n",
    "        return\n",
    "\n",
    "    global num_param_updates\n",
    "    # sample batch from replay memory\n",
    "    batch = np.array(replay_memory.sample(batch_size))#,dtype=float)\n",
    "\n",
    "\n",
    "    # Extract from batch\n",
    "    ss, aa, rr, ss1, dd = np.stack(batch[:,0]), np.stack(batch[:,1]), np.stack(batch[:,2]), np.stack(batch[:,3]), np.stack(batch[:,4]).astype(int)\n",
    "\n",
    "    # Convert to Tensors\n",
    "    ss = torch.from_numpy(ss).float().view(-1,n_inputs)\n",
    "    aa = torch.from_numpy(aa).long().view(-1,1)\n",
    "    rr = torch.from_numpy(rr).float().view(-1,1)\n",
    "    ss1 = torch.from_numpy(ss1).float().view(-1,n_inputs)\n",
    "    dd = torch.from_numpy(dd).float().view(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "    # Forward pass on batch\n",
    "    policy_net.optimizer.zero_grad()\n",
    "    Q = policy_net(ss.float())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the q value for all possible moves\n",
    "        Q1 = policy_net(ss1.float())\n",
    "\n",
    "    yk = Q1.clone()\n",
    "    for k in range(batch_size):\n",
    "        yk_k = rr[k] + gamma * Q1[k].max().item() * (not dd[k])\n",
    "        yk[k, aa[k]] = yk_k\n",
    "\n",
    "    ## update network weights\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(Q, yk)\n",
    "\n",
    "    # Old loss function\n",
    "    #loss = policy_net.loss(Q, yk)\n",
    "\n",
    "    loss.backward()\n",
    "    policy_net.optimizer.step()\n",
    "\n",
    "    num_param_updates += 1\n",
    "\n",
    "    if num_param_updates % target_update_freq == 0:\n",
    "        # update target network parameters from policy network parameters\n",
    "        target_net.load_state_dict(policy_net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary training loop\n",
    "Specify the OpenAI Gym environment, and define hyper parameters.\n",
    "Select if the system should load a previously saved network, if the new network should be saved after training, and if the system should train or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casper/Dropbox/DL/gym/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpaceDiscrete(\n",
      "array([[-1.89855434e-03, -5.31327561e-03,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.20559430e-01,  3.37396440e-01,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.16210292e-06,  1.74810578e-05,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.18335220e-04,  1.20991136e-03,  0.00000000e+00,\n",
      "         9.94166023e-01, -2.50653640e-01],\n",
      "       [-7.87649478e-06,  1.41947131e-05,  0.00000000e+00,\n",
      "         1.99499836e-02,  9.97491020e-01]]),\n",
      "array([[ 4.41690012e-01],\n",
      "       [ 1.96066911e+01],\n",
      "       [ 3.26992751e-04],\n",
      "       [-3.58022490e-02],\n",
      "       [-4.18525342e-04]]),\n",
      "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        , 57.29577951]]),\n",
      "array([[0],\n",
      "       [0]]),\n",
      "dt: 0.02\n",
      ")\n",
      "Number of inputs:  3 , number of outputs:  13\n",
      "Tau:  0.02  Number of steps:  800  Episode duration:  16.0  [s]\n",
      "Fixed states:  [[0.05 0.   0.95]\n",
      " [0.95 0.   0.05]\n",
      " [0.25 0.   0.75]\n",
      " [0.75 0.   0.25]]\n",
      "Start training\n",
      "  10. mean training reward: -608.57, mean validation reward: -2807.24\n",
      "  20. mean training reward: -662.83, mean validation reward: -3223.55\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    " ####### MAIN #######\n",
    "\n",
    "# Import environment\n",
    "env = gym.make('CartPoleCrane-v3')\n",
    "\n",
    "# Number of inputs and outputs\t\n",
    "n_inputs = 3 \n",
    "n_outputs = 13 \n",
    "print(\"Number of inputs: \", n_inputs, \", number of outputs: \", n_outputs)\n",
    "\n",
    "##### train Deep Q-network #####\n",
    "\n",
    "# Parameters\n",
    "num_episodes = 20 # default: 50 # Number of episodes\n",
    "episode_limit = 800 # Length of episode\n",
    "\n",
    "batch_size = 32 # Default: 32\n",
    "learning_rate = 0.002 # Default = 0.002\n",
    "gamma = 0.99 # discount rate\n",
    "replay_memory_capacity = 5000\n",
    "prefill_memory = False\n",
    "val_freq = 10 # validation frequency\n",
    "\n",
    "\n",
    "num_param_updates = 0\n",
    "target_update_freq = 25 # Default 25\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.FloatTensor\n",
    "dlongtype = torch.LongTensor\n",
    "\n",
    "# initialize DQN\n",
    "policy_net = DQN(n_inputs, n_outputs, learning_rate).to(device)\n",
    "target_net = DQN(n_inputs, n_outputs, learning_rate).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "## Load network \n",
    "load = 0\n",
    "save = 0\n",
    "train = 1\n",
    "if load:\n",
    "\tprint(\"Loading network\")\n",
    "\tpolicy_net.load_state_dict(torch.load('pendulumCrane/pretrainedNets/dqn_net.pt'))\n",
    "\ttarget_net.load_state_dict(torch.load('pendulumCrane/pretrainedNets/dqn_net.pt'))\n",
    "\n",
    "if not train:\n",
    "\tprint(\"Skipping Training\")\n",
    "\tdata_array = np.array([0,0,0,0,0,0])\n",
    "\tnum_episodes = 0\n",
    "\n",
    "# Initialize replay memory\n",
    "replay_memory = ReplayMemory(replay_memory_capacity)\n",
    "\n",
    "#eps_check(num_episodes)\n",
    "\n",
    "val_ep = False\n",
    "\n",
    "\n",
    "# Tau from environment\n",
    "tau_agent = env.env.tau\n",
    "print(\"Tau: \", tau_agent, \" Number of steps: \", episode_limit, \" Episode duration: \", tau_agent*episode_limit, \" [s]\")\n",
    "\n",
    "# Collect a set of fixed states for average Q metric\n",
    "state = env.reset()\n",
    "\n",
    "s_fix_1 = state # x, theta, goal\n",
    "s_fix_1[0] = 0.05\n",
    "s_fix_1[2] = 0.95\n",
    "\n",
    "state = env.reset()\n",
    "s_fix_2 = state\n",
    "s_fix_2[0] = 0.95\n",
    "s_fix_2[2] = 0.05\n",
    "\n",
    "state = env.reset()\n",
    "s_fix_3 = state\n",
    "s_fix_3[0] = 0.25\n",
    "s_fix_3[2] = 0.75\n",
    "\n",
    "state = env.reset()\n",
    "s_fix_4 = state\n",
    "s_fix_4[0] = 0.75\n",
    "s_fix_4[2] = 0.25\n",
    "\n",
    "fixed_states = np.array([s_fix_1, s_fix_2, s_fix_3, s_fix_4])\n",
    "print(\"Fixed states: \", fixed_states)\n",
    "\n",
    "Q_average = []\n",
    "\n",
    "output_histogram = np.zeros(n_outputs)\n",
    "reward_array = np.zeros(4)\n",
    "\n",
    "\n",
    "## Training loop\n",
    "print(\"Start training\")\n",
    "rewards, lengths = [], []\n",
    "final_distances = []\n",
    "initial_distances = []\n",
    "state = env.reset()\n",
    "\n",
    "## Data\n",
    "#data_array = np.array([0,0,0,0])\n",
    "#print(\"Size of array :\", data_array.size)\n",
    "\n",
    "\n",
    "epsilon = 1.0\n",
    "\n",
    "step_count = 0\n",
    "max_theta = 0\n",
    "for i in range(num_episodes):\n",
    "\n",
    "\t# Reset environment and values\n",
    "\t# Get initial observation \n",
    "\tstate = env.reset()\n",
    "\tep_reward = 0\n",
    "\tfinal_distance = 0\n",
    "\n",
    "\t# Initialize Action array storage\n",
    "\taction_array = np.array([[0,0,0,0]])\n",
    "\n",
    "\t# Initial distance\n",
    "\tx_goal = state[2]\n",
    "\tx_pos = state[0]\n",
    "\tinitial_distance = x_pos - x_goal\n",
    "\tdistance = initial_distance\n",
    "\n",
    "\tfor j in range(episode_limit):\n",
    "\n",
    "\t\t# Select action based on states, the epsilon greedy strategy and validation episode flag\n",
    "\t\taction_type = select_action(state, step_count)\n",
    "\n",
    "\t\t#if np.random.rand() >= epsilon:\n",
    "\t\tif action_type == \"Q\":\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\t# Get the q value for all possible moves\n",
    "\t\t\t\tq_value_all_actions = policy_net(torch.from_numpy(state).float())\n",
    "\t\t\t\t# Select the action that has the highest value\n",
    "\t\t\t\taction = q_value_all_actions.argmax().item()\n",
    "\n",
    "\t\t\t\t# Update output histogram\n",
    "\t\t\t\toutput_histogram[int(action)] += 1\n",
    "\n",
    "\t\telse:\n",
    "\t\t\taction = random_action(n_outputs)\n",
    "\n",
    "\t\t# Perform action and get results\n",
    "\t\tnumpy_action = D2C(action) # Discrete action as a numpy variable\n",
    "\t\tnext_state, reward_old, done, _ = env.step(numpy_action)\n",
    "\n",
    "\t\t# Old distance\n",
    "\t\told_distance = distance\n",
    "\n",
    "\t\t# New distance \n",
    "\t\tx_goal = next_state[2]\n",
    "\t\tx_pos = next_state[0]\n",
    "\t\tdistance = x_pos - x_goal\n",
    "\n",
    "\n",
    "\t\t# get reward\n",
    "\t\treward, reward_array = agent_reward(numpy_action, next_state, reward_array, state)\n",
    "\n",
    "\t\t# Check if done\n",
    "\t\tif done:\n",
    "\t\t\tlengths.append(j + 1)\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\treplay_memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "\t\t# Perform model optimization (It automatically checks if replay buffer is full)\n",
    "\t\tif (j+1) % 2 == 0:\n",
    "\t\t\tsimple_optimizer(n_inputs)\n",
    "\n",
    "\n",
    "\t\t# bookkeeping\n",
    "\t\tstate = next_state\n",
    "\t\tep_reward += reward\n",
    "\n",
    "\t### End of episode\n",
    "\t\n",
    "\tfinal_distances.append(distance)\n",
    "\trewards.append(ep_reward)\n",
    "\tlengths.append(j+1)\n",
    "\tinitial_distances.append(initial_distance)\n",
    "\n",
    "\n",
    "\n",
    "\tstep_count += 1\n",
    "\t# Validation episode\n",
    "\tif (i+1) % val_freq == 0:\n",
    "\t\tvalidation_rewards = []\n",
    "\t\t#q_diff = []\n",
    "\t\tfor ii in range(4):\n",
    "\t\t\tdata_array = np.array([0,0,0,0,0,0])\n",
    "\t\t\ts = env.reset()\n",
    "\n",
    "\t\t\t# Fixed state for validation\n",
    "\t\t\ts[0] = 0.05 # Start pos\n",
    "\t\t\ts[2] = 0.80 # Goal pos\n",
    "\t\t\tenv.env.state[2] = s[0]\n",
    "\t\t\tenv.env.set_goal(s[2])\n",
    "\n",
    "\t\t\treward_val = 0\n",
    "\t\t\tfor jj in range(episode_limit):\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\t# Get the q value for all possible moves\n",
    "\t\t\t\t\tQ_probs = policy_net(torch.from_numpy(s).float())\n",
    "\t\t\t\t\t# Select the action that has the highest value\n",
    "\t\t\t\t\taction = Q_probs.argmax().item()\n",
    "\n",
    "\t\t\t\ta_env = D2C(action)\n",
    "\t\t\t\ts_new, r_old, done, _ = env.step(a_env)\n",
    "\n",
    "\t\t\t\told_distance = distance\n",
    "\t\t\t\t# Update distance\n",
    "\t\t\t\tx_goal = s[2]\n",
    "\t\t\t\tx_pos = s[0]\n",
    "\t\t\t\tdistance = x_pos - x_goal\n",
    "\n",
    "\t\t\t\t# Calculate actual reward\n",
    "\t\t\t\tr, reward_array = agent_reward(a_env, s_new, reward_array, s)\n",
    "\t\t\t\t#q_diff = qd\n",
    "\n",
    "\t\t\t\ttime_stamp = tau_agent*jj\n",
    "\t\t\t\t## Data \n",
    "\t\t\t\treward_val += r\n",
    "\t\t\t\ts = s_new\n",
    "\t\t\t\tif done: \n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t#print(\"Breaking, ii: \", ii, \" jj: \", jj)\n",
    "\t\t\tvalidation_rewards.append(reward_val)\n",
    "\t\tprint('{:4d}. mean training reward: {:6.2f}, mean validation reward: {:6.2f}'.format(i+1, np.mean(rewards[-val_freq:]), np.mean(validation_rewards)))\n",
    "\n",
    "\t\t# Average Q value on fixed states\n",
    "\t\tQ_ep = []\n",
    "\t\tfor ii in range(4):\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\t# Get the q value for all possible moves\n",
    "\t\t\t\tQ_probs = policy_net(torch.from_numpy(fixed_states[ii]).float())\n",
    "\t\t\t# get the highest value action\n",
    "\t\t\tmax_action = Q_probs.max().item()\n",
    "\t\t\tQ_ep.append(max_action)\n",
    "\t\tQ_average.append(np.mean(Q_ep))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training\n",
    "Functions to save the network, plot general data and display a simulation of the resulting network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpaceDiscrete(\n",
      "array([[-1.89855434e-03, -5.31327561e-03,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.20559430e-01,  3.37396440e-01,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.16210292e-06,  1.74810578e-05,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.18335220e-04,  1.20991136e-03,  0.00000000e+00,\n",
      "         9.94166023e-01, -2.50653640e-01],\n",
      "       [-7.87649478e-06,  1.41947131e-05,  0.00000000e+00,\n",
      "         1.99499836e-02,  9.97491020e-01]]),\n",
      "array([[ 4.41690012e-01],\n",
      "       [ 1.96066911e+01],\n",
      "       [ 3.26992751e-04],\n",
      "       [-3.58022490e-02],\n",
      "       [-4.18525342e-04]]),\n",
      "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        , 57.29577951]]),\n",
      "array([[0],\n",
      "       [0]]),\n",
      "dt: 0.02\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Saving network\n",
    "if save:\n",
    "    print(\"Saving network\")\n",
    "    torch.save(policy_net.state_dict(), './policy_net.pt')\n",
    "\n",
    "## Plot\n",
    "def moving_average(a, n=10) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret / n\n",
    "\n",
    "\n",
    "if train:\n",
    "    fig, ax = plt.subplots(4,1)\n",
    "    ax[0].plot(range(1, len(rewards)+1), rewards, label='training reward')\n",
    "    ax[0].plot(moving_average(rewards))\n",
    "    ax[0].set_xlabel('episode')\n",
    "    ax[0].set_ylabel('reward')\n",
    "    ax[0].grid()\n",
    "\n",
    "    ax[1].plot(range(1, len(final_distances)+1), final_distances,'r', label='final distance')\n",
    "    ax[1].scatter(range(1, len(initial_distances)+1), initial_distances, label='initial distance')\n",
    "    ax[1].set_xlabel('episode')\n",
    "    ax[1].set_ylabel('distance')\n",
    "    ax[1].grid()\n",
    "\n",
    "    ax[2].plot(range(1, len(lengths)+1), lengths, label='episode length')\n",
    "    ax[2].set_xlabel('episode')\n",
    "    ax[2].set_ylabel('length')\n",
    "    ax[2].grid()\n",
    "\n",
    "    ax[3].plot(range(1,len(Q_average)+1), Q_average, label='Average Q')\n",
    "    ax[3].set_xlabel('Validation episode')\n",
    "    ax[3].set_ylabel('Average Q')\n",
    "    ax[3].grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "env.env.close()\n",
    "\n",
    "\n",
    "### VIEWER\n",
    "\n",
    "# Import environment\n",
    "env = gym.make('CartPoleCrane-v3')\n",
    "\n",
    "env.seed(1234)\n",
    "outdir = 'tmp/dqn-agent-results'\n",
    "env = wrappers.Monitor(env, directory=outdir, force=True)\n",
    "\n",
    "s = env.reset()\n",
    "#s = s_fix_1\n",
    "\n",
    "distace = s[0] - s[2]\n",
    "for _ in range(400):\n",
    "    # Get the q value for all possible moves\n",
    "    q_value_all_actions = policy_net(torch.from_numpy(s).float())\n",
    "    # Select the action that has the highest value\n",
    "    action = q_value_all_actions.argmax().item()\n",
    "\n",
    "    # Perform action and get results\n",
    "    numpy_action = D2C(action) # Discrete action as a numpy variable\n",
    "    next_state, reward, done, _ = env.step(numpy_action)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "    s = next_state\n",
    "\n",
    "# Close the env and write monitor result info to disk\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained agent\n",
    "The following pretrained agent performs better but is far from perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casper/Dropbox/DL/gym/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpaceDiscrete(\n",
      "array([[-1.89855434e-03, -5.31327561e-03,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.20559430e-01,  3.37396440e-01,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.16210292e-06,  1.74810578e-05,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.18335220e-04,  1.20991136e-03,  0.00000000e+00,\n",
      "         9.94166023e-01, -2.50653640e-01],\n",
      "       [-7.87649478e-06,  1.41947131e-05,  0.00000000e+00,\n",
      "         1.99499836e-02,  9.97491020e-01]]),\n",
      "array([[ 4.41690012e-01],\n",
      "       [ 1.96066911e+01],\n",
      "       [ 3.26992751e-04],\n",
      "       [-3.58022490e-02],\n",
      "       [-4.18525342e-04]]),\n",
      "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        , 57.29577951]]),\n",
      "array([[0],\n",
      "       [0]]),\n",
      "dt: 0.02\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "policy_net.load_state_dict(torch.load('pendulumCrane/pretrainedNets/dqn_net.pt'))\n",
    "\n",
    "### VIEWER\n",
    "\n",
    "# Import environment\n",
    "env = gym.make('CartPoleCrane-v3')\n",
    "\n",
    "env.seed(1234)\n",
    "outdir = 'tmp/dqn-agent-results'\n",
    "env = wrappers.Monitor(env, directory=outdir, force=True)\n",
    "\n",
    "s = env.reset()\n",
    "#s = s_fix_1\n",
    "\n",
    "distace = s[0] - s[2]\n",
    "for _ in range(400):\n",
    "    # Get the q value for all possible moves\n",
    "    q_value_all_actions = policy_net(torch.from_numpy(s).float())\n",
    "    # Select the action that has the highest value\n",
    "    action = q_value_all_actions.argmax().item()\n",
    "\n",
    "    # Perform action and get results\n",
    "    numpy_action = D2C(action) # Discrete action as a numpy variable\n",
    "    next_state, reward, done, _ = env.step(numpy_action)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "    s = next_state\n",
    "\n",
    "# Close the env and write monitor result info to disk\n",
    "env.env.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
